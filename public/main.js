// HTMLã‹ã‚‰è¦ç´ ã‚’å–å¾—
const videoElement = document.getElementById('input_video');
const canvasElement = document.getElementById('output_canvas');
const canvasCtx = canvasElement.getContext('2d');

// UIè¦ç´ 
const statusElement = document.getElementById('status');
const startFrontBtn = document.getElementById('startFrontCamera');
const startBackBtn = document.getElementById('startBackCamera');
const stopBtn = document.getElementById('stopCamera');

// Socket.IOã¨WebRTCã®åˆæœŸåŒ–
const socket = io();
let peerConnection = null;
let dataChannel = null;

// MediaPipeé–¢é€£
let hands = null;
let currentStream = null;
let isHandsReady = false;
let isRunning = false;
let animationFrameId = null;

// WebRTCã®è¿½åŠ å¤‰æ•°
let iceCandidateBuffer = [];
let isDescriptionSet = false;

// ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°é–¢æ•°
function updateStatus(message, type = 'loading') {
Â  Â  statusElement.textContent = message;
Â  Â  statusElement.className = `status ${type}`;
}

// UIçŠ¶æ…‹æ›´æ–°
function updateUIState(state) {
Â  Â  switch (state) {
Â  Â  Â  Â  case 'initializing':
Â  Â  Â  Â  Â  Â  startFrontBtn.disabled = true;
Â  Â  Â  Â  Â  Â  startBackBtn.disabled = true;
Â  Â  Â  Â  Â  Â  stopBtn.classList.add('hidden');
Â  Â  Â  Â  Â  Â  break;
Â  Â  Â  Â  case 'ready':
Â  Â  Â  Â  Â  Â  startFrontBtn.disabled = false;
Â  Â  Â  Â  Â  Â  startBackBtn.disabled = false;
Â  Â  Â  Â  Â  Â  stopBtn.classList.add('hidden');
Â  Â  Â  Â  Â  Â  break;
Â  Â  Â  Â  case 'running':
Â  Â  Â  Â  Â  Â  startFrontBtn.disabled = true;
Â  Â  Â  Â  Â  Â  startBackBtn.disabled = true;
Â  Â  Â  Â  Â  Â  stopBtn.classList.remove('hidden');
Â  Â  Â  Â  Â  Â  break;
Â  Â  }
}

// MediaPipe Handsã®åˆæœŸåŒ–
async function initializeHands() {
Â  Â  try {
Â  Â  Â  Â  updateStatus('MediaPipe HandsåˆæœŸåŒ–ä¸­...', 'loading');
Â  Â  Â  Â  updateUIState('initializing');

Â  Â  Â  Â  hands = new Hands({
Â  Â  Â  Â  Â  Â  locateFile: (file) => {
Â  Â  Â  Â  Â  Â  Â  Â  return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  });

Â  Â  Â  Â  hands.setOptions({
Â  Â  Â  Â  Â  Â  maxNumHands: 2,
Â  Â  Â  Â  Â  Â  modelComplexity: 1,
Â  Â  Â  Â  Â  Â  minDetectionConfidence: 0.5,
Â  Â  Â  Â  Â  Â  minTrackingConfidence: 0.5
Â  Â  Â  Â  });

Â  Â  Â  Â  hands.onResults(onHandsResults);
Â  Â  Â  Â  await hands.initialize();

Â  Â  Â  Â  isHandsReady = true;
Â  Â  Â  Â  updateStatus('æº–å‚™å®Œäº† - ã‚«ãƒ¡ãƒ©ã‚’é¸æŠã—ã¦ãã ã•ã„', 'ready');
Â  Â  Â  Â  updateUIState('ready');

Â  Â  Â  Â  console.log('MediaPipe Hands initialized successfully');

Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('MediaPipe HandsåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', error);
Â  Â  Â  Â  updateStatus(`åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: ${error.message}`, 'error');
Â  Â  }
}

// æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯å‡¦ç†çµæœ
function onHandsResults(results) {
Â  Â  const videoRect = videoElement.getBoundingClientRect();
Â  Â  canvasElement.width = videoRect.width;
Â  Â  canvasElement.height = videoRect.height;

Â  Â  canvasCtx.save();
Â  Â  canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
Â  Â  canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

Â  Â  if (results.multiHandLandmarks) {
Â  Â  Â  Â  for (const landmarks of results.multiHandLandmarks) {
Â  Â  Â  Â  Â  Â  drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, {
Â  Â  Â  Â  Â  Â  Â  Â  color: '#00FF00',
Â  Â  Â  Â  Â  Â  Â  Â  lineWidth: Math.max(2, canvasElement.width / 320)
Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  Â  Â  drawLandmarks(canvasCtx, landmarks, {
Â  Â  Â  Â  Â  Â  Â  Â  color: '#FF0000',
Â  Â  Â  Â  Â  Â  Â  Â  lineWidth: Math.max(1, canvasElement.width / 480),
Â  Â  Â  Â  Â  Â  Â  Â  radius: Math.max(2, canvasElement.width / 320)
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  }

Â  Â  Â  Â  if (dataChannel && dataChannel.readyState === 'open') {
Â  Â  Â  Â  Â  Â  // â˜… ä¿®æ­£ç®‡æ‰€: ãƒ©ãƒƒãƒ‘ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å‰Šé™¤ã—ã€ç”Ÿã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯é…åˆ—ã‚’é€ä¿¡
Â  Â  Â  Â  Â  Â  const handData = JSON.stringify(results.multiHandLandmarks);
Â  Â  Â  Â  Â  Â  dataChannel.send(handData);
Â  Â  Â  Â  Â  Â  console.log('âœ… Sent RAW hand landmarks array to Unity via DataChannel.');
Â  Â  Â  Â  }
Â  Â  }

Â  Â  canvasCtx.restore();
}

// ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’MediaPipeã«é€ä¿¡ã™ã‚‹ãƒ«ãƒ¼ãƒ—
function sendToMediaPipe() {
Â  Â  if (isRunning && isHandsReady) {
Â  Â  Â  Â  hands.send({ image: videoElement });
Â  Â  Â  Â  animationFrameId = requestAnimationFrame(sendToMediaPipe);
Â  Â  }
}

async function startCamera(facingMode = 'environment') {
Â  Â  try {
Â  Â  Â  Â  const cameraType = facingMode === 'user' ? 'å‰é¢' : 'èƒŒé¢';
Â  Â  Â  Â  updateStatus(`${cameraType}ã‚«ãƒ¡ãƒ©é–‹å§‹ä¸­...`, 'loading');
Â  Â  Â  Â  updateUIState('initializing');

Â  Â  Â  Â  await stopCamera(false);

Â  Â  Â  Â  const constraints = {
Â  Â  Â  Â  Â  Â  video: {
Â  Â  Â  Â  Â  Â  Â  Â  facingMode: facingMode,
Â  Â  Â  Â  Â  Â  Â  Â  width: { ideal: 1280, max: 1920 },
Â  Â  Â  Â  Â  Â  Â  Â  height: { ideal: 720, max: 1080 },
Â  Â  Â  Â  Â  Â  Â  Â  frameRate: { ideal: 30, max: 60 }
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  };

Â  Â  Â  Â  const stream = await navigator.mediaDevices.getUserMedia(constraints);
Â  Â  Â  Â  videoElement.srcObject = stream;
Â  Â  Â  Â  currentStream = stream;
Â  Â  Â  Â  isRunning = true;

Â  Â  Â  Â  videoElement.onloadeddata = () => {
Â  Â  Â  Â  Â  Â  console.log('Video stream loaded.');
Â  Â  Â  Â  Â  Â  videoElement.play();
Â  Â  Â  Â  Â  Â  sendToMediaPipe();
Â  Â  Â  Â  Â  Â  updateStatus(`${cameraType}ã‚«ãƒ¡ãƒ©ã§å‹•ä½œä¸­`, 'running');
Â  Â  Â  Â  Â  Â  updateUIState('running');
Â  Â  Â  Â  };

Â  Â  Â  Â  console.log(`Camera started with ${cameraType} facing mode`);

Â  Â  } catch (error) {
Â  Â  Â  Â  console.error(`ã‚«ãƒ¡ãƒ©é–‹å§‹ã‚¨ãƒ©ãƒ¼ (${facingMode}):`, error);
Â  Â  Â  Â  updateStatus(`ã‚«ãƒ¡ãƒ©ã‚¨ãƒ©ãƒ¼: ${error.message}`, 'error');
Â  Â  Â  Â  updateUIState('ready');
Â  Â  }
}

async function stopCamera(updateUI = true) {
Â  Â  try {
Â  Â  Â  Â  isRunning = false;

Â  Â  Â  Â  if (animationFrameId) {
Â  Â  Â  Â  Â  Â  cancelAnimationFrame(animationFrameId);
Â  Â  Â  Â  Â  Â  animationFrameId = null;
Â  Â  Â  Â  }

Â  Â  Â  Â  if (currentStream) {
Â  Â  Â  Â  Â  Â  currentStream.getTracks().forEach(track => {
Â  Â  Â  Â  Â  Â  Â  Â  track.stop();
Â  Â  Â  Â  Â  Â  Â  Â  console.log(`Stopped track: ${track.kind}`);
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  currentStream = null;
Â  Â  Â  Â  }

Â  Â  Â  Â  videoElement.srcObject = null;
Â  Â  Â  Â  canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

Â  Â  Â  Â  if (updateUI) {
Â  Â  Â  Â  Â  Â  updateStatus('æº–å‚™å®Œäº† - ã‚«ãƒ¡ãƒ©ã‚’é¸æŠã—ã¦ãã ã•ã„', 'ready');
Â  Â  Â  Â  Â  Â  updateUIState('ready');
Â  Â  Â  Â  }

Â  Â  Â  Â  console.log('Camera stopped successfully');

Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('ã‚«ãƒ¡ãƒ©åœæ­¢ã‚¨ãƒ©ãƒ¼:', error);
Â  Â  }
}

function handleResize() {
Â  Â  if (isRunning && videoElement.videoWidth && videoElement.videoHeight) {
Â  Â  Â  Â  const videoRect = videoElement.getBoundingClientRect();
Â  Â  Â  Â  canvasElement.width = videoRect.width;
Â  Â  Â  Â  canvasElement.height = videoRect.height;
Â  Â  }
}

function setupEventListeners() {
Â  Â  startFrontBtn.addEventListener('click', async () => {
Â  Â  Â  Â  await startCamera('user');
Â  Â  Â  Â  initializeWebRTC();
Â  Â  });
Â  Â  startBackBtn.addEventListener('click', async () => {
Â  Â  Â  Â  await startCamera('environment');
Â  Â  Â  Â  initializeWebRTC();
Â  Â  });
Â  Â  stopBtn.addEventListener('click', () => {
Â  Â  Â  Â  stopCamera();
Â  Â  Â  Â  if (peerConnection) {
Â  Â  Â  Â  Â  Â  peerConnection.close();
Â  Â  Â  Â  Â  Â  peerConnection = null;
Â  Â  Â  Â  Â  Â  socket.emit('webrtc_close');
Â  Â  Â  Â  }
Â  Â  Â  Â  dataChannel = null;
Â  Â  });

Â  Â  window.addEventListener('resize', handleResize);
Â  Â  window.addEventListener('beforeunload', () => stopCamera(false));
Â  Â  document.addEventListener('visibilitychange', () => {
Â  Â  Â  Â  if (document.hidden && isRunning) {
Â  Â  Â  Â  Â  Â  console.log('Page hidden - pausing camera');
Â  Â  Â  Â  } else if (!document.hidden && isRunning) {
Â  Â  Â  Â  Â  Â  console.log('Page visible - resuming camera');
Â  Â  Â  Â  }
Â  Â  });
}

window.addEventListener('DOMContentLoaded', async (event) => {
Â  Â  console.log('DOM fully loaded and parsed');
Â  Â  setupEventListeners();
Â  Â  await initializeHands();
});

// PWAãŒWebRTCæ¥ç¶šã‚’é–‹å§‹ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯
function initializeWebRTC() {
Â  Â  if (peerConnection) {
Â  Â  Â  Â  peerConnection.close();
Â  Â  Â  Â  peerConnection = null;
Â  Â  }
Â  Â  if (dataChannel) {
Â  Â  Â  Â  dataChannel.close();
Â  Â  Â  Â  dataChannel = null;
Â  Â  }

Â  Â  iceCandidateBuffer = [];
Â  Â  isDescriptionSet = false;
Â  Â  console.log('Initializing WebRTC.');

Â  Â  peerConnection = new RTCPeerConnection({
Â  Â  Â  Â  iceServers: [
Â  Â  Â  Â  Â  Â  { urls: 'stun:stun.l.google.com:19302' },
Â  Â  Â  Â  Â  Â  { urls: 'stun:stun1.l.google.com:19302' },
Â  Â  Â  Â  Â  Â  { urls: 'stun:stun2.l.google.com:19302' },
Â  Â  Â  Â  Â  Â  { urls: 'stun:stun.services.mozilla.com:3478' },
Â  Â  Â  Â  Â  Â  { urls: 'stun:stun.voip.blackberry.com:3478' }
Â  Â  Â  Â  ]
Â  Â  });

Â  Â  dataChannel = peerConnection.createDataChannel('handData', {
Â  Â  Â  Â  ordered: false,
Â  Â  Â  Â  maxRetransmits: 0
Â  Â  });

Â  Â  dataChannel.onopen = () => {
Â  Â  Â  Â  console.log('Data Channel is open!');
Â  Â  Â  Â  updateStatus('Unityã¨WebRTCæ¥ç¶šå®Œäº†', 'success');
Â  Â  };

Â  Â  dataChannel.onclose = () => {
Â  Â  Â  Â  console.log('Data Channel closed');
Â  Â  };

Â  Â  dataChannel.onerror = (error) => {
Â  Â  Â  Â  console.error('Data Channel error:', error);
Â  Â  };

Â  Â  peerConnection.onicecandidate = (e) => {
Â  Â  Â  Â  if (e.candidate) {
Â  Â  Â  Â  Â  Â  console.log('Found and sending ICE candidate:', JSON.stringify(e.candidate));

Â  Â  Â  Â  Â  Â  let candidateStr = e.candidate.candidate;
Â  Â  Â  Â  Â  Â  candidateStr = candidateStr.replace(/\sufrag\s\S+/, '');
Â  Â  Â  Â  Â  Â  candidateStr = candidateStr.replace(/\snetwork-id\s\S+/, '');
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  const candidateObj = {
Â  Â  Â  Â  Â  Â  Â  Â  candidate: candidateStr,
Â  Â  Â  Â  Â  Â  Â  Â  sdpMid: e.candidate.sdpMid,
Â  Â  Â  Â  Â  Â  Â  Â  sdpMLineIndex: e.candidate.sdpMLineIndex,
Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  socket.emit('candidate', candidateObj);
Â  Â  Â  Â  Â  Â  console.log('âœ… PWAã‹ã‚‰é€ä¿¡ã™ã‚‹Candidate JSON (ä¿®æ­£å¾Œ):', candidateObj);
Â  Â  Â  Â  }
Â  Â  };

Â  Â  peerConnection.onnegotiationneeded = async () => {
Â  Â  Â  Â  console.log('Negotiation needed event fired. Creating and sending Offer.');
Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  const offer = await peerConnection.createOffer();
Â  Â  Â  Â  Â  Â  await peerConnection.setLocalDescription(offer);
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  const offerObj = {
Â  Â  Â  Â  Â  Â  Â  Â  type: 'offer',
Â  Â  Â  Â  Â  Â  Â  Â  sdp: peerConnection.localDescription.sdp,
Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  Â  socket.emit('offer', offerObj);
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  isDescriptionSet = false;
Â  Â  Â  Â  Â  Â  console.log('PWA created and sent offer.');
Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  console.error('Error creating and sending offer:', e);
Â  Â  Â  Â  }
Â  Â  };

Â  Â  peerConnection.onconnectionstatechange = () => {
Â  Â  Â  Â  if (peerConnection.connectionState === 'disconnected' || peerConnection.connectionState === 'failed') {
Â  Â  Â  Â  Â  Â  stopCamera();
Â  Â  Â  Â  Â  Â  if (peerConnection) {
Â  Â  Â  Â  Â  Â  Â  Â  peerConnection.close();
Â  Â  Â  Â  Â  Â  Â  Â  peerConnection = null;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  dataChannel = null;
Â  Â  Â  Â  Â  Â  updateStatus('WebRTCæ¥ç¶šå¤±æ•— - å†è©¦è¡Œã—ã¦ãã ã•ã„', 'error');
Â  Â  Â  Â  }
Â  Â  };

Â  Â  socket.on('answer', async (answer) => {
Â  Â  Â  Â  console.log('ğŸ’™ Unityã‹ã‚‰Answerã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚');

Â  Â  Â  Â  let answerObj = answer;
Â  Â  Â  Â  if (typeof answer === 'string') {
Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  answerObj = JSON.parse(answer);
Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  console.error('Error parsing answer JSON:', e);
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  console.log('âœ… å—ä¿¡ã—ãŸAnswer JSON:', answerObj);
Â  Â  Â  Â  
Â  Â  Â  Â  if (peerConnection && peerConnection.signalingState === 'have-local-offer' &&
Â  Â  Â  Â  Â  Â  answerObj && answerObj.sdp && answerObj.type === 'answer') {
Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  await peerConnection.setRemoteDescription(new RTCSessionDescription(answerObj));
Â  Â  Â  Â  Â  Â  Â  Â  isDescriptionSet = true;
Â  Â  Â  Â  Â  Â  Â  Â  for (const candidate of iceCandidateBuffer) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  await peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  iceCandidateBuffer = [];
Â  Â  Â  Â  Â  Â  Â  Â  console.log('Successfully set remote description and added buffered candidates.');
Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  console.error('Error setting remote description for answer:', e);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  console.error('Invalid state or answer object:', peerConnection?.signalingState, answerObj);
Â  Â  Â  Â  }
Â  Â  });

Â  Â  socket.on('candidate', async (candidate) => {
Â  Â  Â  Â  console.log('ğŸ’™ Unityã‹ã‚‰Candidateã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚');

Â  Â  Â  Â  let candidateObj = candidate;
Â  Â  Â  Â  if (typeof candidate === 'string') {
Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  candidateObj = JSON.parse(candidate);
Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  console.error('Error parsing candidate JSON:', e);
Â  Â  Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  console.log('âœ… å—ä¿¡ã—ãŸCandidate JSON:', candidateObj);

Â  Â  Â  Â  if (candidateObj && candidateObj.candidate) {
Â  Â  Â  Â  Â  Â  if (isDescriptionSet) {
Â  Â  Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  await peerConnection.addIceCandidate(new RTCIceCandidate(candidateObj));
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.log('ICE candidate added immediately.');
Â  Â  Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.error('Error adding received ICE candidate immediately:', e);
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  iceCandidateBuffer.push(candidateObj);
Â  Â  Â  Â  Â  Â  Â  Â  console.log('ICE candidate buffered.');
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  console.error('Received invalid ICE candidate object:', candidateObj);
Â  Â  Â  Â  }
Â  Â  });
}

// Socket.IOæ¥ç¶šã‚¤ãƒ™ãƒ³ãƒˆ
socket.on('connect', () => {
Â  Â  socket.emit('register_role', 'staff');
Â  Â  updateStatus('Unityã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å¾…æ©Ÿä¸­...', 'loading');
});

socket.on('webrtc_close', () => {
Â  Â  stopCamera();
Â  Â  if (peerConnection) {
Â  Â  Â  Â  peerConnection.close();
Â  Â  Â  Â  peerConnection = null;
Â  Â  }
Â  Â  dataChannel = null;
Â  Â  updateStatus('WebRTCæ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¾ã—ãŸ', 'error');
});

socket.on('connect_error', (error) => {
Â  Â  updateStatus('ã‚µãƒ¼ãƒãƒ¼æ¥ç¶šã‚¨ãƒ©ãƒ¼', 'error');
});

socket.on('disconnect', (reason) => {
Â  Â  updateStatus('ã‚µãƒ¼ãƒãƒ¼åˆ‡æ–­', 'error');
Â  Â  if (peerConnection) {
Â  Â  Â  Â  peerConnection.close();
Â  Â  Â  Â  peerConnection = null;
Â  Â  }
Â  Â  dataChannel = null;
});