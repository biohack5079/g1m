// HTMLã‹ã‚‰è¦ç´ ã‚’å–å¾—
const videoElement = document.getElementById('input_video');
const canvasElement = document.getElementById('output_canvas');
const canvasCtx = canvasElement.getContext('2d');

// UIè¦ç´ 
const statusElement = document.getElementById('status');
const startFrontBtn = document.getElementById('startFrontCamera');
const startBackBtn = document.getElementById('startBackCamera');
const stopBtn = document.getElementById('stopCamera');

// Socket.IOã¨WebRTCã®åˆæœŸåŒ–
const socket = io();
let peerConnection = null;
let dataChannel = null;

// MediaPipeé–¢é€£
let hands = null;
let currentStream = null;
let isHandsReady = false;
let isRunning = false;
let animationFrameId = null; 

// WebRTCã®è¿½åŠ å¤‰æ•°
let iceCandidateBuffer = [];
let isDescriptionSet = false;
let isNegotiating = false;

// ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°é–¢æ•°
function updateStatus(message, type = 'loading') {
Â  Â  statusElement.textContent = message;
Â  Â  statusElement.className = `status ${type}`;
}

// UIçŠ¶æ…‹æ›´æ–°
function updateUIState(state) {
Â  Â  switch(state) {
Â  Â  Â  Â  case 'initializing':
Â  Â  Â  Â  Â  Â  startFrontBtn.disabled = true;
Â  Â  Â  Â  Â  Â  startBackBtn.disabled = true;
Â  Â  Â  Â  Â  Â  stopBtn.classList.add('hidden');
Â  Â  Â  Â  Â  Â  break;
Â  Â  Â  Â  case 'ready':
Â  Â  Â  Â  Â  Â  startFrontBtn.disabled = false;
Â  Â  Â  Â  Â  Â  startBackBtn.disabled = false;
Â  Â  Â  Â  Â  Â  stopBtn.classList.add('hidden');
Â  Â  Â  Â  Â  Â  break;
Â  Â  Â  Â  case 'running':
Â  Â  Â  Â  Â  Â  startFrontBtn.disabled = true;
Â  Â  Â  Â  Â  Â  startBackBtn.disabled = false;
Â  Â  Â  Â  Â  Â  stopBtn.classList.remove('hidden');
Â  Â  Â  Â  Â  Â  break;
Â  Â  }
}

// MediaPipe Handsã®åˆæœŸåŒ–
async function initializeHands() {
Â  Â  try {
Â  Â  Â  Â  updateStatus('MediaPipe HandsåˆæœŸåŒ–ä¸­...', 'loading');
Â  Â  Â  Â  updateUIState('initializing');

Â  Â  Â  Â  hands = new Hands({
Â  Â  Â  Â  Â  Â  locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
Â  Â  Â  Â  });

Â  Â  Â  Â  hands.setOptions({
Â  Â  Â  Â  Â  Â  maxNumHands: 2,
Â  Â  Â  Â  Â  Â  modelComplexity: 1,
Â  Â  Â  Â  Â  Â  minDetectionConfidence: 0.5,
Â  Â  Â  Â  Â  Â  minTrackingConfidence: 0.5
Â  Â  Â  Â  });

Â  Â  Â  Â  hands.onResults(onHandsResults);
Â  Â  Â  Â  await hands.initialize();
Â  Â  Â  Â  
Â  Â  Â  Â  isHandsReady = true;
Â  Â  Â  Â  updateStatus('æº–å‚™å®Œäº† - ã‚«ãƒ¡ãƒ©ã‚’é¸æŠžã—ã¦ãã ã•ã„', 'ready');
Â  Â  Â  Â  updateUIState('ready');
Â  Â  Â  Â  
Â  Â  Â  Â  console.log('MediaPipe Hands initialized successfully');
Â  Â  Â  Â  
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('MediaPipe HandsåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', error);
Â  Â  Â  Â  updateStatus(`åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: ${error.message}`, 'error');
Â  Â  }
}

// æ‰‹ã®ãƒ©ãƒ³ãƒ‰ãƒžãƒ¼ã‚¯å‡¦ç†çµæžœ
function onHandsResults(results) {
Â  Â  const videoRect = videoElement.getBoundingClientRect();
Â  Â  canvasElement.width = videoRect.width;
Â  Â  canvasElement.height = videoRect.height;
Â  Â  
Â  Â  canvasCtx.save();
Â  Â  canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
Â  Â  canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

Â  Â  if (results.multiHandLandmarks) {
Â  Â  Â  Â  for (const landmarks of results.multiHandLandmarks) {
Â  Â  Â  Â  Â  Â  drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, { 
Â  Â  Â  Â  Â  Â  Â  Â  color: '#00FF00', 
Â  Â  Â  Â  Â  Â  Â  Â  lineWidth: Math.max(2, canvasElement.width / 320)
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  drawLandmarks(canvasCtx, landmarks, { 
Â  Â  Â  Â  Â  Â  Â  Â  color: '#FF0000', 
Â  Â  Â  Â  Â  Â  Â  Â  lineWidth: Math.max(1, canvasElement.width / 480),
Â  Â  Â  Â  Â  Â  Â  Â  radius: Math.max(2, canvasElement.width / 320)
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  }

Â  Â  Â  Â  if (dataChannel && dataChannel.readyState === 'open') {
Â  Â  Â  Â  Â  Â  const handData = JSON.stringify(results.multiHandLandmarks);
Â  Â  Â  Â  Â  Â  dataChannel.send(handData);
Â  Â  Â  Â  }
Â  Â  }
Â  Â  
Â  Â  canvasCtx.restore();
}

// ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’MediaPipeã«é€ä¿¡ã™ã‚‹ãƒ«ãƒ¼ãƒ—
function sendToMediaPipe() {
Â  Â  if (isRunning && isHandsReady) {
Â  Â  Â  Â  hands.send({ image: videoElement });
Â  Â  Â  Â  animationFrameId = requestAnimationFrame(sendToMediaPipe);
Â  Â  }
}

async function startCamera(facingMode = 'environment') {
Â  Â  try {
Â  Â  Â  Â  const cameraType = facingMode === 'user' ? 'å‰é¢' : 'èƒŒé¢';
Â  Â  Â  Â  updateStatus(`${cameraType}ã‚«ãƒ¡ãƒ©é–‹å§‹ä¸­...`, 'loading');
Â  Â  Â  Â  updateUIState('initializing');

Â  Â  Â  Â  await stopCamera(false);

Â  Â  Â  Â  const constraints = {
Â  Â  Â  Â  Â  Â  video: {
Â  Â  Â  Â  Â  Â  Â  Â  facingMode: facingMode,
Â  Â  Â  Â  Â  Â  Â  Â  width: { ideal: 1280, max: 1920 },
Â  Â  Â  Â  Â  Â  Â  Â  height: { ideal: 720, max: 1080 },
Â  Â  Â  Â  Â  Â  Â  Â  frameRate: { ideal: 30, max: 60 }
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  };

Â  Â  Â  Â  const stream = await navigator.mediaDevices.getUserMedia(constraints);
Â  Â  Â  Â  videoElement.srcObject = stream;
Â  Â  Â  Â  currentStream = stream;
Â  Â  Â  Â  isRunning = true;

Â  Â  Â  Â  videoElement.onloadeddata = () => {
Â  Â  Â  Â  Â  Â  console.log('Video stream loaded.');
Â  Â  Â  Â  Â  Â  videoElement.play();
Â  Â  Â  Â  Â  Â  sendToMediaPipe();
Â  Â  Â  Â  Â  Â  updateStatus(`${cameraType}ã‚«ãƒ¡ãƒ©ã§å‹•ä½œä¸­`, 'ready');
Â  Â  Â  Â  Â  Â  updateUIState('running');
Â  Â  Â  Â  };

Â  Â  Â  Â  console.log(`Camera started with ${cameraType} facing mode`);

Â  Â  } catch (error) {
Â  Â  Â  Â  console.error(`ã‚«ãƒ¡ãƒ©é–‹å§‹ã‚¨ãƒ©ãƒ¼ (${facingMode}):`, error);
Â  Â  Â  Â  updateStatus(`ã‚«ãƒ¡ãƒ©ã‚¨ãƒ©ãƒ¼: ${error.message}`, 'error');
Â  Â  Â  Â  updateUIState('ready');
Â  Â  }
}

async function stopCamera(updateUI = true) {
Â  Â  try {
Â  Â  Â  Â  isRunning = false;
Â  Â  Â  Â  
Â  Â  Â  Â  if (animationFrameId) {
Â  Â  Â  Â  Â  Â  cancelAnimationFrame(animationFrameId);
Â  Â  Â  Â  Â  Â  animationFrameId = null;
Â  Â  Â  Â  }

Â  Â  Â  Â  if (currentStream) {
Â  Â  Â  Â  Â  Â  currentStream.getTracks().forEach(track => {
Â  Â  Â  Â  Â  Â  Â  Â  track.stop();
Â  Â  Â  Â  Â  Â  Â  Â  console.log(`Stopped track: ${track.kind}`);
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  currentStream = null;
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  videoElement.srcObject = null;
Â  Â  Â  Â  canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
Â  Â  Â  Â  
Â  Â  Â  Â  if (updateUI) {
Â  Â  Â  Â  Â  Â  updateStatus('æº–å‚™å®Œäº† - ã‚«ãƒ¡ãƒ©ã‚’é¸æŠžã—ã¦ãã ã•ã„', 'ready');
Â  Â  Â  Â  Â  Â  updateUIState('ready');
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('ã‚«ãƒ¡ãƒ©åœæ­¢ã‚¨ãƒ©ãƒ¼:', error);
Â  Â  }
}

function handleResize() {
Â  Â  if (isRunning && videoElement.videoWidth && videoElement.videoHeight) {
Â  Â  Â  Â  const videoRect = videoElement.getBoundingClientRect();
Â  Â  Â  Â  canvasElement.width = videoRect.width;
Â  Â  Â  Â  canvasElement.height = videoRect.height;
Â  Â  }
}

function setupEventListeners() {
Â  Â  startFrontBtn.addEventListener('click', async () => {
Â  Â  Â  Â  await startCamera('user');
Â  Â  });
Â  Â  startBackBtn.addEventListener('click', async () => {
Â  Â  Â  Â  await startCamera('environment');
Â  Â  });
Â  Â  stopBtn.addEventListener('click', () => {
Â  Â  Â  Â  stopCamera();
Â  Â  Â  Â  // WebRTCæŽ¥ç¶šã‚‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
Â  Â  Â  Â  if (peerConnection) {
Â  Â  Â  Â  Â  Â  peerConnection.close();
Â  Â  Â  Â  Â  Â  peerConnection = null;
Â  Â  Â  Â  }
Â  Â  Â  Â  dataChannel = null;
Â  Â  });
Â  Â  
Â  Â  window.addEventListener('resize', handleResize);
Â  Â  window.addEventListener('beforeunload', () => stopCamera(false));
Â  Â  document.addEventListener('visibilitychange', () => {
Â  Â  Â  Â  if (document.hidden && isRunning) {
Â  Â  Â  Â  Â  Â  console.log('Page hidden - pausing camera');
Â  Â  Â  Â  } else if (!document.hidden && isRunning) {
Â  Â  Â  Â  Â  Â  console.log('Page visible - resuming camera');
Â  Â  Â  Â  }
Â  Â  });
}

window.addEventListener('DOMContentLoaded', async (event) => {
Â  Â  console.log('DOM fully loaded and parsed');
Â  Â  setupEventListeners();
Â  Â  await initializeHands();
});


function initializeWebRTC() {
Â  Â  peerConnection?.close();
Â  Â  dataChannel?.close();
Â  Â  peerConnection = null;
Â  Â  dataChannel = null;
Â  Â  iceCandidateBuffer = [];
Â  Â  isDescriptionSet = false;
Â  Â  isNegotiating = false;

Â  Â  console.log('Initializing WebRTC.');

Â  Â  peerConnection = new RTCPeerConnection({
Â  Â  Â  Â  iceServers: [
Â  Â  Â  Â  Â  Â  { urls: 'stun:stun.l.google.com:19302' },
Â  Â  Â  Â  Â  Â  { urls: 'stun:stun1.l.google.com:19302' },
Â  Â  Â  Â  Â  Â  { urls: 'stun:stun2.l.google.com:19302' },
Â  Â  Â  Â  Â  Â  { urls: 'stun:stun.services.mozilla.com:3478' },
Â  Â  Â  Â  Â  Â  { urls: 'stun:stun.voip.blackberry.com:3478' }
Â  Â  Â  Â  ]
Â  Â  });
Â  Â  
Â  Â  dataChannel = peerConnection.createDataChannel('handData', {
Â  Â  Â  Â  ordered: false,
Â  Â  Â  Â  maxRetransmits: 0
Â  Â  });
Â  Â  
Â  Â  dataChannel.onopen = () => {
Â  Â  Â  Â  console.log('Data Channel is open!');
Â  Â  Â  Â  updateStatus('Unityã¨WebRTCæŽ¥ç¶šå®Œäº†', 'success');
Â  Â  };
Â  Â  
Â  Â  dataChannel.onclose = () => {
Â  Â  Â  Â  console.log('Data Channel closed');
Â  Â  };
Â  Â  
Â  Â  dataChannel.onerror = (error) => {
Â  Â  Â  Â  console.error('Data Channel error:', error);
Â  Â  };

Â  Â  peerConnection.onicecandidate = (e) => {
Â  Â  Â  Â  if (e.candidate) {
Â  Â  Â  Â  Â  Â  console.log('Found and sending ICE candidate:', JSON.stringify(e.candidate));
Â  Â  Â  Â  Â  Â  socket.emit('candidate', e.candidate);
Â  Â  Â  Â  }
Â  Â  };
Â  Â  
Â  Â  peerConnection.onnegotiationneeded = async () => {
Â  Â  Â  Â  if (isNegotiating) return;
Â  Â  Â  Â  isNegotiating = true;
Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  console.log('onnegotiationneeded triggered. Creating offer...');
Â  Â  Â  Â  Â  Â  const offer = await peerConnection.createOffer();
Â  Â  Â  Â  Â  Â  await peerConnection.setLocalDescription(offer);
Â  Â  Â  Â  Â  Â  socket.emit('offer', peerConnection.localDescription);
Â  Â  Â  Â  Â  Â  console.log('ðŸ’™ Offerã‚’ä½œæˆã—ã€ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡ã—ã¾ã—ãŸã€‚');
Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  console.error('Error creating offer:', e);
Â  Â  Â  Â  } finally {
Â  Â  Â  Â  Â  Â  isNegotiating = false;
Â  Â  Â  Â  }
Â  Â  };

Â  Â  peerConnection.onconnectionstatechange = () => {
Â  Â  Â  Â  console.log('WebRTC connection state:', peerConnection.connectionState);
Â  Â  Â  Â  if (['disconnected', 'failed', 'closed'].includes(peerConnection.connectionState)) {
Â  Â  Â  Â  Â  Â  console.warn('WebRTC connection failed or disconnected. Closing peer connection.');
Â  Â  Â  Â  Â  Â  peerConnection?.close();
Â  Â  Â  Â  Â  Â  peerConnection = null;
Â  Â  Â  Â  Â  Â  dataChannel = null;
Â  Â  Â  Â  Â  Â  updateStatus('WebRTCæŽ¥ç¶šå¤±æ•—ã¾ãŸã¯åˆ‡æ–­', 'error');
Â  Â  Â  Â  }
Â  Â  };

Â  Â  // Unityã‹ã‚‰ã®Answerã‚’å—ä¿¡ã—ãŸæ™‚ã®å‡¦ç†
Â  Â  socket.on('answer', async (answer) => {
Â  Â  Â  Â  console.log('Received answer from Unity client.');
Â  Â  Â  Â  console.log('ðŸ’™ Unityã‹ã‚‰Answerã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚');
Â  Â  Â  Â  if (!peerConnection || peerConnection.signalingState === 'closed') return;
Â  Â  Â  Â  
Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  let parsedAnswer = typeof answer === 'string' ? JSON.parse(answer) : answer;
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  if (parsedAnswer.type === 2) {
Â  Â  Â  Â  Â  Â  Â  Â  parsedAnswer.type = 'answer';
Â  Â  Â  Â  Â  Â  } else if (parsedAnswer.type === 1) {
Â  Â  Â  Â  Â  Â  Â  Â  parsedAnswer.type = 'offer';
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (peerConnection.signalingState === 'have-local-offer') {
Â  Â  Â  Â  Â  Â  Â  Â  await peerConnection.setRemoteDescription(new RTCSessionDescription(parsedAnswer));
Â  Â  Â  Â  Â  Â  Â  Â  isDescriptionSet = true;
Â  Â  Â  Â  Â  Â  Â  Â  console.log('WebRTC answer received and set.');
Â  Â  Â  Â  Â  Â  Â  Â  console.log('ðŸ’™ Answerã‚’ãƒªãƒ¢ãƒ¼ãƒˆè¨˜è¿°ã«è¨­å®šã—ã¾ã—ãŸã€‚');
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  console.log(`Adding ${iceCandidateBuffer.length} buffered ICE candidates.`);
Â  Â  Â  Â  Â  Â  Â  Â  for (const candidate of iceCandidateBuffer) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  await peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.log('Buffered ICE candidate added successfully.');
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.error('Error adding buffered ICE candidate:', e, candidate);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  iceCandidateBuffer = [];
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  console.warn('setRemoteDescriptionã‚’å‘¼ã¹ã‚‹çŠ¶æ…‹ã«ã‚ã‚Šã¾ã›ã‚“ã€‚çŠ¶æ…‹:', peerConnection.signalingState);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  console.error('Error setting remote description:', e);
Â  Â  Â  Â  }
Â  Â  });

Â  Â  // Unityã‹ã‚‰ã®ICE Candidateã‚’å—ä¿¡ã—ãŸæ™‚ã®å‡¦ç† (ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°å¯¾å¿œ)
Â  Â  socket.on('candidate', async (candidate) => {
Â  Â  Â  Â  console.log('Received ICE candidate from Unity client.');
Â  Â  Â  Â  console.log('ðŸ’™ Unityã‹ã‚‰Candidateã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚');

Â  Â  Â  Â  if (!candidate) {
Â  Â  Â  Â  Â  Â  console.warn('Candidate is null or undefined, skipping.');
Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  }

Â  Â  Â  Â  let parsed;
Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  parsed = typeof candidate === 'string' ? JSON.parse(candidate) : candidate;
Â  Â  Â  Â  } catch (err) {
Â  Â  Â  Â  Â  Â  console.error('Failed to parse candidate JSON:', err, candidate);
Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  }

Â  Â  Â  Â  // candidateæ–‡å­—åˆ—ã®æœ‰ç„¡ã¨å½¢å¼ã‚’åŽ³å¯†ã«ãƒã‚§ãƒƒã‚¯
Â  Â  Â  Â  if (!parsed.candidate || typeof parsed.candidate !== 'string' || !parsed.candidate.trim()) {
Â  Â  Â  Â  Â  Â  console.warn('Skipping invalid candidate:', parsed);
Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  // 'a=' ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ã™ã‚‹
Â  Â  Â  Â  if (parsed.candidate.startsWith('a=')) {
Â  Â  Â  Â  Â  Â  console.log("Trimming 'a=' prefix from candidate string.");
Â  Â  Â  Â  Â  Â  parsed.candidate = parsed.candidate.substring(2);
Â  Â  Â  Â  }

Â  Â  Â  Â  // sdpMidã¨sdpMLineIndexãŒnullã‚„undefinedã®å ´åˆã€é©åˆ‡ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
Â  Â  Â  Â  const finalCandidate = {
Â  Â  Â  Â  Â  Â  candidate: parsed.candidate,
Â  Â  Â  Â  Â  Â  sdpMid: parsed.sdpMid !== undefined && parsed.sdpMid !== null ? parsed.sdpMid : '',
Â  Â  Â  Â  Â  Â  sdpMLineIndex: parsed.sdpMLineIndex !== undefined && parsed.sdpMLineIndex !== null ? parsed.sdpMLineIndex : 0
Â  Â  Â  Â  };
Â  Â  Â  Â  
Â  Â  Â  Â  if (isDescriptionSet && peerConnection.signalingState === 'stable') {
Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  await peerConnection.addIceCandidate(new RTCIceCandidate(finalCandidate));
Â  Â  Â  Â  Â  Â  Â  Â  console.log('ICE candidate added immediately.');
Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  console.error('Error adding received ICE candidate immediately:', e, finalCandidate);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  iceCandidateBuffer.push(finalCandidate);
Â  Â  Â  Â  Â  Â  console.log('ICE candidate buffered.');
Â  Â  Â  Â  }
Â  Â  });
}


// Socket.IOæŽ¥ç¶šã‚¤ãƒ™ãƒ³ãƒˆ
socket.on('connect', () => {
Â  Â  console.log('Socket connected.');
Â  Â  // PWAã®å½¹å‰²ã‚’ã‚µãƒ¼ãƒãƒ¼ã«é€šçŸ¥
Â  Â  socket.emit('register_role', 'staff');
Â  Â  updateStatus('Unityã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å¾…æ©Ÿä¸­...', 'loading');
});

// ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰WebRTCæŽ¥ç¶šé–‹å§‹ã®æŒ‡ç¤ºã‚’å—ã‘å–ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ
socket.on('start_webrtc', async () => {
Â  Â  console.log('Received start_webrtc event from server. Initializing WebRTC.');
Â  Â  // ã‚«ãƒ¡ãƒ©ãŒèµ·å‹•ã—ã¦ã„ãªã‘ã‚Œã°ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§èƒŒé¢ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•
Â  Â  if (!isRunning) {
Â  Â  Â  Â  await startCamera('environment');
Â  Â  }
Â  Â  initializeWebRTC();
});


// ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰åˆ‡æ–­é€šçŸ¥ã‚’å—ã‘å–ã£ãŸæ™‚ã®å‡¦ç†
socket.on('webrtc_close', () => {
Â  Â  console.log('Received webrtc_close event. Stopping camera and closing peer connection.');
Â  Â  stopCamera();
Â  Â  if (peerConnection) {
Â  Â  Â  Â  peerConnection.close();
Â  Â  Â  Â  peerConnection = null;
Â  Â  }
Â  Â  dataChannel = null;
Â  Â  updateStatus('WebRTCæŽ¥ç¶šãŒåˆ‡æ–­ã•ã‚Œã¾ã—ãŸ', 'error');
});

// ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
socket.on('connect_error', (error) => {
Â  Â  console.error('Socket connection error:', error);
Â  Â  updateStatus('ã‚µãƒ¼ãƒãƒ¼æŽ¥ç¶šã‚¨ãƒ©ãƒ¼', 'error');
});

socket.on('disconnect', (reason) => {
Â  Â  console.log('Socket disconnected:', reason);
Â  Â  updateStatus('ã‚µãƒ¼ãƒãƒ¼åˆ‡æ–­', 'error');
Â  Â  if (peerConnection) {
Â  Â  Â  Â  peerConnection.close();
Â  Â  Â  Â  peerConnection = null;
Â  Â  }
Â  Â  dataChannel = null;
});

window.addEventListener('DOMContentLoaded', async (event) => {
Â  Â  console.log('DOM fully loaded and parsed');
Â  Â  setupEventListeners();
Â  Â  await initializeHands();
});